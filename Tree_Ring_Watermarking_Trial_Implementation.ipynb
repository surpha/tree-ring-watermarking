{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNC67kKs0uPh+PK+Zcu1Ion",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surpha/tree-ring-watermarking/blob/main/Tree_Ring_Watermarking_Trial_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U9bVydmMbdG",
        "outputId": "d10772b0-dd72-4e4a-8b02-10ea1542db75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m662.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0) (4.10.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m529.0/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.0\n",
        "!pip install transformers==4.23.1\n",
        "!pip install diffusers==0.11.1\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/YuxinWenRick/tree-ring-watermark.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXVY12r-N964",
        "outputId": "1df4fc4a-8e11-4a45-d315-455921f24158"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tree-ring-watermark'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 211 (delta 36), reused 29 (delta 25), pack-reused 160\u001b[K\n",
            "Receiving objects: 100% (211/211), 6.03 MiB | 21.83 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "\n",
        "%cd tree-ring-watermark/\n",
        "\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNU_x432PgF4",
        "outputId": "69f0ecbc-df42-4f29-8d36-691122ac73ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtree-ring-watermark\u001b[0m/\n",
            "/content/tree-ring-watermark\n",
            "256x256_diffusion.json        README.md\n",
            "\u001b[0m\u001b[01;34mguided_diffusion\u001b[0m/             requirements.txt\n",
            "inverse_stable_diffusion.py   run_tree_ring_watermark_fid.py\n",
            "io_utils.py                   run_tree_ring_watermark_imagenet_fid.py\n",
            "LICENSE.md                    run_tree_ring_watermark_imagenet.py\n",
            "Makefile                      run_tree_ring_watermark.py\n",
            "modified_stable_diffusion.py  \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;34mopen_clip\u001b[0m/                    setup.py\n",
            "optim_utils.py                \u001b[01;34msrc\u001b[0m/\n",
            "\u001b[01;34mpytorch_fid\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyCFQQrcPtXg",
        "outputId": "dfa5b76f-a299-434d-f99e-7c2aa7c141d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.44.0-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m264.9/264.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.44.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "oh-rkphTP4N0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqICkJSpR5gn",
        "outputId": "fb483dd4-1194-4571-85a2-46eb56981dc5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Collecting torch==2.2.1 (from torchvision)\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m969.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0\n",
            "    Uninstalling torch-1.13.0:\n",
            "      Successfully uninstalled torch-1.13.0\n",
            "Successfully installed torch-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ftfy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V_K30mASTMb",
        "outputId": "dea43f70-f373-4df7-ee85-910fd4232587"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m933.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_tree_ring_watermark.py --run_name no_attack --w_channel 3 --w_pattern ring --start 0 --end 1000 --with_tracking --reference_model ViT-g-14 --reference_model_pretrain laion2b_s12b_b42k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWRM69fcOp9P",
        "outputId": "66d5bae8-3786-4b95-f2d3-07a7c95db342"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/tree-ring-watermark/wandb/run-20240329_221751-g0z0x2xf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mno_attack\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dlbits/diffusion_watermark\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dlbits/diffusion_watermark/runs/g0z0x2xf/workspace\u001b[0m\n",
            "scheduler/scheduler_config.json: 100% 346/346 [00:00<00:00, 648kB/s]\n",
            "model_index.json: 100% 517/517 [00:00<00:00, 787kB/s]\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "tokenizer/special_tokens_map.json: 100% 460/460 [00:00<00:00, 338kB/s]\n",
            "Fetching 12 files:  17% 2/12 [00:00<00:02,  4.66it/s]\n",
            "tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "unet/config.json: 100% 976/976 [00:00<00:00, 2.00MB/s]\n",
            "\n",
            "\n",
            "vae/config.json: 100% 617/617 [00:00<00:00, 1.47MB/s]\n",
            "\n",
            "\n",
            "tokenizer/tokenizer_config.json: 100% 824/824 [00:00<00:00, 1.99MB/s]\n",
            "\n",
            "\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 7.46MB/s]\n",
            "\n",
            "text_encoder/config.json: 100% 633/633 [00:00<00:00, 1.48MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 23.7MB/s]\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/681M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model.bin:   3% 21.0M/681M [00:00<00:03, 203MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   0% 0.00/1.73G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   6% 10.5M/167M [00:00<00:01, 86.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   6% 41.9M/681M [00:00<00:05, 118MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   1% 10.5M/1.73G [00:00<00:47, 36.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:   9% 62.9M/681M [00:00<00:06, 101MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  19% 31.5M/167M [00:00<00:02, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   2% 31.5M/1.73G [00:00<00:36, 46.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  12% 83.9M/681M [00:00<00:07, 85.0MB/s]\u001b[A\n",
            "pytorch_model.bin:  14% 94.4M/681M [00:01<00:06, 84.5MB/s]\u001b[A\n",
            "pytorch_model.bin:  15% 105M/681M [00:01<00:09, 61.7MB/s] \u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  31% 52.4M/167M [00:01<00:02, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  18% 126M/681M [00:01<00:06, 85.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 62.9M/167M [00:01<00:02, 47.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   3% 52.4M/1.73G [00:01<00:44, 37.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  44% 73.4M/167M [00:01<00:01, 55.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   4% 73.4M/1.73G [00:01<00:29, 56.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  22% 147M/681M [00:01<00:06, 77.5MB/s]\u001b[A\n",
            "pytorch_model.bin:  23% 157M/681M [00:01<00:06, 75.2MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   5% 83.9M/1.73G [00:01<00:35, 46.7MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  26% 178M/681M [00:02<00:05, 89.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  50% 83.9M/167M [00:01<00:02, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  28% 189M/681M [00:02<00:05, 83.7MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   6% 105M/1.73G [00:02<00:30, 52.9MB/s] \u001b[A\u001b[A\n",
            "pytorch_model.bin:  31% 210M/681M [00:02<00:06, 73.4MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   7% 126M/1.73G [00:02<00:30, 52.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  32% 220M/681M [00:02<00:06, 72.9MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   8% 136M/1.73G [00:02<00:27, 57.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  63% 105M/167M [00:02<00:01, 32.9MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  75% 126M/167M [00:02<00:00, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  35% 241M/681M [00:03<00:06, 70.5MB/s]\u001b[A\n",
            "pytorch_model.bin:  38% 262M/681M [00:03<00:05, 73.9MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:   9% 157M/1.73G [00:03<00:35, 44.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  43% 294M/681M [00:03<00:03, 96.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  81% 136M/167M [00:03<00:00, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  10% 178M/1.73G [00:03<00:26, 59.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  46% 315M/681M [00:03<00:04, 79.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  94% 157M/167M [00:03<00:00, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  11% 189M/1.73G [00:03<00:32, 47.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  49% 336M/681M [00:04<00:03, 86.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin: 100% 167M/167M [00:04<00:00, 41.6MB/s]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  12% 199M/1.73G [00:04<00:33, 46.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  51% 346M/681M [00:04<00:04, 78.0MB/s]\u001b[A\n",
            "pytorch_model.bin:  54% 367M/681M [00:04<00:03, 92.3MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  12% 210M/1.73G [00:04<00:32, 47.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  57% 388M/681M [00:04<00:02, 110MB/s] \u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  13% 220M/1.73G [00:04<00:27, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  14% 241M/1.73G [00:04<00:24, 60.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  60% 409M/681M [00:04<00:03, 82.1MB/s]\u001b[A\n",
            "pytorch_model.bin:  62% 419M/681M [00:05<00:03, 85.2MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  15% 252M/1.73G [00:04<00:24, 59.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  63% 430M/681M [00:05<00:02, 86.2MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  15% 262M/1.73G [00:05<00:29, 49.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  66% 451M/681M [00:05<00:02, 90.0MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  16% 273M/1.73G [00:05<00:25, 56.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  68% 461M/681M [00:05<00:02, 83.5MB/s]\u001b[A\n",
            "pytorch_model.bin:  69% 472M/681M [00:07<00:12, 17.3MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  17% 294M/1.73G [00:07<01:21, 17.7MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  71% 482M/681M [00:07<00:09, 21.7MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  18% 304M/1.73G [00:07<01:11, 20.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  72% 493M/681M [00:08<00:07, 25.0MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  18% 315M/1.73G [00:08<00:56, 24.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  74% 503M/681M [00:08<00:05, 30.9MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  19% 325M/1.73G [00:08<00:46, 30.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  75% 514M/681M [00:08<00:04, 38.4MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  20% 346M/1.73G [00:08<00:30, 45.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  79% 535M/681M [00:08<00:02, 52.3MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  21% 357M/1.73G [00:08<00:26, 51.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  82% 556M/681M [00:08<00:01, 69.6MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  22% 377M/1.73G [00:08<00:19, 69.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  85% 577M/681M [00:08<00:01, 85.0MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  23% 398M/1.73G [00:08<00:20, 65.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  89% 608M/681M [00:09<00:00, 92.7MB/s]\u001b[A\n",
            "pytorch_model.bin:  92% 629M/681M [00:09<00:00, 85.3MB/s]\u001b[A\n",
            "pytorch_model.bin:  95% 650M/681M [00:09<00:00, 98.4MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  24% 419M/1.73G [00:09<00:25, 51.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  99% 671M/681M [00:09<00:00, 99.0MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin: 100% 681M/681M [00:09<00:00, 69.1MB/s]\n",
            "Fetching 12 files:  33% 4/12 [00:10<00:31,  3.88s/it]\n",
            "\n",
            "diffusion_pytorch_model.bin:  26% 451M/1.73G [00:10<00:30, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  27% 472M/1.73G [00:10<00:31, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  29% 503M/1.73G [00:11<00:23, 52.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  30% 524M/1.73G [00:11<00:23, 52.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  32% 556M/1.73G [00:12<00:20, 56.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  33% 577M/1.73G [00:12<00:19, 60.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  35% 598M/1.73G [00:12<00:15, 73.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  35% 608M/1.73G [00:12<00:15, 70.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  36% 629M/1.73G [00:12<00:15, 72.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 650M/1.73G [00:13<00:11, 90.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  39% 671M/1.73G [00:13<00:13, 79.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  39% 682M/1.73G [00:13<00:16, 65.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  40% 692M/1.73G [00:13<00:15, 67.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  41% 713M/1.73G [00:14<00:18, 54.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  42% 734M/1.73G [00:14<00:19, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  44% 755M/1.73G [00:15<00:17, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  44% 765M/1.73G [00:15<00:19, 50.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  45% 786M/1.73G [00:15<00:18, 52.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  47% 807M/1.73G [00:15<00:13, 68.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  47% 818M/1.73G [00:16<00:18, 49.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  48% 839M/1.73G [00:16<00:20, 44.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  50% 870M/1.73G [00:17<00:17, 49.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  51% 891M/1.73G [00:18<00:18, 44.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  53% 912M/1.73G [00:18<00:14, 57.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  53% 923M/1.73G [00:18<00:15, 53.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  54% 944M/1.73G [00:18<00:14, 55.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  56% 965M/1.73G [00:18<00:10, 72.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  57% 986M/1.73G [00:19<00:12, 58.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  58% 996M/1.73G [00:19<00:17, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  59% 1.02G/1.73G [00:20<00:12, 56.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  59% 1.03G/1.73G [00:20<00:14, 48.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  61% 1.05G/1.73G [00:20<00:15, 44.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  62% 1.08G/1.73G [00:21<00:11, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  64% 1.10G/1.73G [00:21<00:12, 52.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  65% 1.12G/1.73G [00:21<00:09, 66.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  65% 1.13G/1.73G [00:22<00:12, 48.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  67% 1.15G/1.73G [00:22<00:13, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  68% 1.18G/1.73G [00:23<00:11, 48.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  70% 1.21G/1.73G [00:24<00:12, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  71% 1.23G/1.73G [00:24<00:09, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  71% 1.24G/1.73G [00:24<00:10, 47.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  73% 1.26G/1.73G [00:25<00:12, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  74% 1.28G/1.73G [00:25<00:08, 52.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  74% 1.29G/1.73G [00:25<00:10, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  76% 1.31G/1.73G [00:26<00:10, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  77% 1.33G/1.73G [00:26<00:07, 55.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  77% 1.34G/1.73G [00:27<00:08, 44.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  79% 1.36G/1.73G [00:27<00:07, 48.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  80% 1.38G/1.73G [00:27<00:05, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  81% 1.39G/1.73G [00:27<00:06, 52.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  82% 1.42G/1.73G [00:28<00:06, 47.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  83% 1.44G/1.73G [00:28<00:05, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  84% 1.45G/1.73G [00:29<00:06, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  85% 1.47G/1.73G [00:29<00:06, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  87% 1.50G/1.73G [00:30<00:04, 51.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  88% 1.52G/1.73G [00:30<00:04, 48.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  89% 1.54G/1.73G [00:30<00:03, 60.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  90% 1.55G/1.73G [00:31<00:03, 49.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  91% 1.57G/1.73G [00:31<00:03, 40.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  93% 1.60G/1.73G [00:32<00:02, 49.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  94% 1.63G/1.73G [00:32<00:02, 45.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  95% 1.65G/1.73G [00:32<00:01, 56.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  96% 1.66G/1.73G [00:33<00:01, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  97% 1.68G/1.73G [00:33<00:01, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  97% 1.69G/1.73G [00:34<00:01, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin:  99% 1.71G/1.73G [00:34<00:00, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.bin: 100% 1.73G/1.73G [00:35<00:00, 49.5MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:35<00:00,  2.99s/it]\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "open_clip_pytorch_model.bin: 100% 5.47G/5.47G [02:15<00:00, 40.3MB/s]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_tree_ring_watermark.py --run_name no_attack --w_channel 3 --w_pattern ring --start 0 --end 1000 --with_tracking --reference_model ViT-g-14 --reference_model_pretrain laion2b_s12b_b42k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dOA9WcJT4c9",
        "outputId": "e624bde2-3a07-4021-e59a-0951417b612a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-29 22:24:39.971121: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-29 22:24:39.971207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-29 22:24:39.972889: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-29 22:24:41.334943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/tree-ring-watermark/run_tree_ring_watermark.py\", line 10, in <module>\n",
            "    from inverse_stable_diffusion import InversableStableDiffusionPipeline\n",
            "  File \"/content/tree-ring-watermark/inverse_stable_diffusion.py\", line 7, in <module>\n",
            "    from diffusers.models import AutoencoderKL, UNet2DConditionModel\n",
            "ModuleNotFoundError: No module named 'diffusers'\n"
          ]
        }
      ]
    }
  ]
}